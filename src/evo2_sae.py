# -*- coding: utf-8 -*-
"""evo2_sae.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNsK0GQC7Um2X2t4j4A66etLjSfhLRil

## Import and setup
"""

import os

import matplotlib.pyplot as plt
import numpy as np
import torch

from evaluate_feature import calculate_AUC_matrix, calculate_precision_matrix
from models.mcclain_thiel_sae import SparseAutoencoder
from numpytrack_to_bedfile import track_to_bed, track_to_bedgraph

"""## Mount google drive"""

# from google.colab import drive
# import os
#
# gdrive_path='/content/gdrive/MyDrive/ml4rg-data'
#
# # This will mount your google drive under 'MyDrive'
# drive.mount('/content/gdrive', force_remount=True)
# # In order to access the files in this notebook we have to navigate to the correct folder
# os.chdir(gdrive_path)
# # Check manually if all files are present
# print(sorted(os.listdir()))

raw_data_dir = "/s/project/ml4rg_students/2025/project02/raw"
group_data_dir = "/s/project/ml4rg_students/2025/project02/group-1"

emb_path = os.path.join(raw_data_dir, "layer_11_embeddings.npy")
emb = np.load(emb_path)
emb.shape

input_dim = emb.shape[-1]
sae = SparseAutoencoder(input_dim=input_dim, expansion_factor=12)
sae

"""GPU is required for training this, else this takes forever"""

emb_tensor = torch.from_numpy(emb)
n_seqs = emb.shape[0]
val_size = int(n_seqs * 0.2)
train_emb_tensor, val_emb_tensor = torch.split(
    emb_tensor, [n_seqs - val_size, val_size]
)

sae.train_model(
    train_emb_tensor,
    val_activations=val_emb_tensor,
    batch_size=16,
    num_epochs=1, # 50
    checkpoint_dir=os.path.join(group_data_dir, "mcclain-thiel-sae"),
)

sae.plot_training_metrics(save_path=os.path.join(group_data_dir, "mcclain-thiel-sae/training_metrics.png"))

"""The `get_feature_vectors` method actually gets the model weights, not the activations.

We are interested in the activations
"""

sae.get_feature_vectors()[0]

emb_tensor[0].shape

"""The sae encoder activations are what we are interested in"""

# TODO: somehow do this in a batched way to avoid oom
activations = sae.encode(emb_tensor.to(sae.device))
activations

activations.shape

"""Now we load the ground truth"""

groundtruth_path = os.path.join(
    raw_data_dir, "chip_exo_57_TF_binding_sites.npy"
)
groundtruth = np.load(groundtruth_path)

groundtruth_int = groundtruth.astype(int)

groundtruth_int = groundtruth_int[:, :, -1]

activations_np = activations.cpu().numpy()

"""For the AUC calculations we need to do some reshaping"""

groundtruth_int = groundtruth_int.reshape(n_seqs * 1003, 1)
activations_np = activations_np.reshape(n_seqs * 1003, activations_np.shape[-1])

"""We don't need these anymore, so let's delete them to prevent colab from crashing"""

del sae
del emb
del emb_tensor

aucs = calculate_AUC_matrix(activations_np, groundtruth_int)

tfbs_feature_auroc = aucs.max()
tfbs_feature_auroc_idx = np.where(aucs == tfbs_feature_auroc)[0][0]

seq_idx = 9

example_act = activations_np.reshape(n_seqs, 1003, activations_np.shape[-1])[
    seq_idx, :, tfbs_feature_auroc_idx
]
example_gt = groundtruth_int.reshape(n_seqs, 1003)[seq_idx]

track_to_bedgraph(example_act, os.path.join(group_data_dir, f"mcclain-thiel-sae/seq{seq_idx}_activations.bedgraph"))
track_to_bed(example_gt, os.path.join(group_data_dir, f"mcclain-thiel-sae/seq{seq_idx}_groundtruth.bed"))

from sklearn.metrics import RocCurveDisplay, roc_curve

fpr, tpr, _ = roc_curve(
    groundtruth_int.reshape(n_seqs * 1003, 1),
    activations_np[:, tfbs_feature_auroc_idx].reshape(n_seqs * 1003, 1),
)
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()
plt.savefig(os.path.join(group_data_dir, f"mcclain-thiel-sae/roc_curve.png"))

"""Let's take a look at the precision"""

precisions = calculate_precision_matrix(
    activations_np.reshape(n_seqs * 1003, activations_np.shape[-1]),
    groundtruth_int.reshape(n_seqs * 1003, 1),
)
precisions

precisions[tfbs_feature_auroc_idx], precisions.max()

print(
    f"""
============REPORT============
Max AUROC: {tfbs_feature_auroc}
Feature index: {tfbs_feature_auroc_idx}
Max AUROC feature precision: {precisions[tfbs_feature_auroc_idx]}
Max precision: {precisions.max()}
"""
)

